{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeoOhkPPrzKJFOXj2wDNWp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kospi-2025/EVT/blob/main/ADtest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lmoments3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkAntKXsLwt9",
        "outputId": "b7e6d95b-46d9-4598-973d-5a84e04ae03a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Aee9-a6MLXvV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/kospi-2025/EVT/main/\"\n",
        "\n",
        "df = pd.read_csv(base_url + \"source_data/\" + \"ticker_info.csv\")\n",
        "df['id'] = df['id'].astype(str).str.zfill(6)\n",
        "df['Yahoo_Ticker'] = df['id'] + \".KS\"\n",
        "\n",
        "ticker_to_name = dict(zip(df[\"Yahoo_Ticker\"], df[\"name\"]))\n",
        "ticker_to_sector = dict(zip(df[\"Yahoo_Ticker\"], df[\"sector\"]))"
      ],
      "metadata": {
        "id": "y4rUHenNLaUe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logDD = pd.read_csv(base_url + \"logDD.csv\", index_col=0)\n",
        "MRL = pd.read_csv(base_url + \"MRL.csv\")"
      ],
      "metadata": {
        "id": "ANMIKPJCLczt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPGpZxcVLPCQ",
        "outputId": "7686c23d-cc34-4bce-d0f8-d9a5e3061608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19008 [00:00<?, ?it/s]<ipython-input-19-6afc6b4e0847>:18: RuntimeWarning: divide by zero encountered in log\n",
            "  term = (2 * i - 1) * (np.log(F) + np.log(1 - F[::-1]))\n",
            "100%|██████████| 19008/19008 [1:03:00<00:00,  5.03it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import genpareto\n",
        "import lmoments3 as lm\n",
        "\n",
        "from lmoments3 import distr\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load MRL results (already computed)\n",
        "mrl_df = MRL\n",
        "\n",
        "# Function to compute Anderson-Darling statistic\n",
        "def ad_statistic(data, cdf):\n",
        "    data_sorted = np.sort(data)\n",
        "    n = len(data_sorted)\n",
        "    F = cdf(data_sorted)\n",
        "    i = np.arange(1, n + 1)\n",
        "    term = (2 * i - 1) * (np.log(F) + np.log(1 - F[::-1]))\n",
        "    return -n - np.mean(term)\n",
        "\n",
        "# Parameters\n",
        "n_bootstrap = 100\n",
        "min_exceedances = 10\n",
        "\n",
        "# Results\n",
        "results_mle = []\n",
        "results_lmom = []\n",
        "\n",
        "# Main loop\n",
        "for _, row in tqdm(mrl_df.iterrows(), total=len(mrl_df)):\n",
        "    ticker = row['Ticker']\n",
        "    u = row['Threshold']\n",
        "\n",
        "    # Replace with your actual logDD source\n",
        "    series = logDD[ticker].dropna()\n",
        "    excesses = series[series > u] - u\n",
        "\n",
        "    if len(excesses) < min_exceedances:\n",
        "        continue\n",
        "\n",
        "    ## --- MLE-based GPD fit --- ##\n",
        "    try:\n",
        "        c_mle, loc_mle, scale_mle = genpareto.fit(excesses, floc=0)\n",
        "        ad_emp_mle = ad_statistic(excesses, lambda x: genpareto.cdf(x, c_mle, loc=0, scale=scale_mle))\n",
        "\n",
        "        ad_boot_mle = [\n",
        "            ad_statistic(genpareto.rvs(c=c_mle, scale=scale_mle, size=len(excesses)),\n",
        "                         lambda x: genpareto.cdf(x, c_mle, loc=0, scale=scale_mle))\n",
        "            for _ in range(n_bootstrap)\n",
        "        ]\n",
        "        pval_mle = np.mean(np.array(ad_boot_mle) > ad_emp_mle)\n",
        "\n",
        "        results_mle.append({\n",
        "            \"Ticker\": ticker, \"Threshold\": u, \"Quantile\": row[\"Quantile\"], \"MRL\": row[\"MRL\"],\n",
        "            \"Method\": \"MLE\", \"AD_Stat\": ad_emp_mle, \"p_value\": pval_mle,\n",
        "            \"xi_hat\": c_mle, \"beta_hat\": scale_mle, \"n_excess\": len(excesses)\n",
        "        })\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "    ## --- L-moment-based GPD fit --- ##\n",
        "    try:\n",
        "        paras = distr.gpa.lmom_fit(excesses)\n",
        "        gpa_fitted = distr.gpa(**paras)\n",
        "        ad_emp_lmom = ad_statistic(excesses, gpa_fitted.cdf)\n",
        "\n",
        "        ad_boot_lmom = [\n",
        "            ad_statistic(gpa_fitted.rvs(size=len(excesses)), gpa_fitted.cdf)\n",
        "            for _ in range(n_bootstrap)\n",
        "        ]\n",
        "        pval_lmom = np.mean(np.array(ad_boot_lmom) > ad_emp_lmom)\n",
        "\n",
        "        results_lmom.append({\n",
        "            \"Ticker\": ticker, \"Threshold\": u, \"Quantile\": row[\"Quantile\"], \"MRL\": row[\"MRL\"],\n",
        "            \"Method\": \"L-Moment\", \"AD_Stat\": ad_emp_lmom, \"p_value\": pval_lmom,\n",
        "            \"xi_hat\": paras[\"c\"], \"beta_hat\": paras[\"scale\"], \"n_excess\": len(excesses)\n",
        "        })\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "# Convert to DataFrames\n",
        "df_mle = pd.DataFrame(results_mle)\n",
        "df_lmom = pd.DataFrame(results_lmom)\n",
        "\n",
        "# Save\n",
        "df_mle.to_csv(\"ad_test_results_mle.csv\", index=False)\n",
        "df_lmom.to_csv(\"ad_test_results_lmoment.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFsFkjihVrm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}